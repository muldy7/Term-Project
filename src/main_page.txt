/*! \mainpage ME-405 Term Project Main Page
 *
 * \section intro_sec Introduction
 *
 * This main page serves as a brief summary of the code and its implementation used
 * to create our Nerf turret for the ME-405 Term Project. The code is documentated in 
 * more detail in the generated documentation that can be found on this website.
 * 
 * \section files_sec Files
 * 
 * To create our final robot, we used a combination of testing files, classes, and main 
 * files. The files are explained in more detail below. The final robot used five classes and 
 * one main file that ran the code from a laptop. The classes allow use to use an encoder, 
 * motor driver, pd controller, servo driver, and a camera. All these functions were used in 
 * the final implementation of the robot. 
 * 
 * \subsection main Main Project Code Files
 * 
 * project_main.py: This file implements code to run our robot in a line-by-line code 
 * basis. We used this file from a laptop during the final tournament and testing. This code uses
 * all the classes to turn the robot 180 degrees, wait for 5 seconds, capture a thermal
 * image, move to the target, shoot the target, and then stop. This was written in a similar 
 * way to our scheduler, which is detailed, along with its states, below. Our scheduler has the 
 * ability to move the robot multiple times, which we had some trouble with perfecting before the 
 * tournament. The project_main.py just moves the robot once before shooting. Since the code is also
 * not split into tasks it makes it easier to print all of the values used to find the target for 
 * easier tuning of the targetting algorithim. 
 *
 * scheduler_main.py: This file implementated our robot using tasks and a scheduler. The code
 * worked in a very similar way to project_main, except it splits the camera and the motor 
 * controlling into two seperate tasks. The explanation of these states and tasks is detailed 
 * in the 'Tasks and States' section below. 
 *
 * \subsection classes Project Classes
 * The following classes are the ones written to for use in the creation and implementation 
 * of our robot. 
 *
 * pd_controller.py: This file creates a class that implements a PD controller that we 
 * used to control our robot. The PD control was used in all elements of our motor movement
 * in our main code to spin the robot and find targets. There are also a controller.py and pid_controller.py
 * file that work in a similar way but were not used on our final robot. 
 * 
 * encoder_reader.py: This file creates an encoder class that allows use to use the encoder on the
 * motor we used. The encoder class allows use to measure the movement of the motor for calculation of 
 * our motor's movement that can be used along with the previous pd_controller to control the robot. 
 * 
 * mlx_cam.py: This file was given to us, and creates a class that allows use to use a thermal camera
 * that can find targets for our robot to shoot at. Our group added another function, get_hotspot, 
 * takes images from the camera and calculates the location of the target in encoder tics. This 
 * encoder tic value was then given to our motor controller so the robot could point and shoot at
 * targets in the project_main.py code. 
 * 
 * motor_driver.py: This file creates a motor_driver class to control the motor powering our robot. 
 * A motor object created with this class can be given a PWM value and will spin the motor at that  
 * PWM. This file was used in conjuction with the encoder and controller to move the robot. 
 * 
 * servo_driver.py: This file creates a servo class for controlling a servo motor. We created a servo
 * class for controlling the servo that pulled the trigger of our gun. Sending the servo object a
 * desired angle will spin the servo to that angle. 
 * 
 * \subsection test Test Code
 * 
 * gui_tuning.py: This file contains code to run program on a laptop or desktop which creates a user
 * interface that can send a signal to the microcontroller to run a step response. The user can set a
 * Kp, Kd, and Setpoint values and send that to a microcontroller where a Controller Object will read
 * and interpret the data from the motor. This code was used to tune our robot for different step 
 * responses during its use. Using the code below we found the best Kp and Kd values for the 180
 * degree turn, which we found to be different than the optimal gain values for smaller turns that
 * would occur while finding a target.
 * 
 * main.py: This file contains code that was stored on our group's Nucleo board to generate the motor
 * step-response. This file was called by the code on our computer and read through the serial port to
 * generate graphs of our step-response.
 * 
 * \section states_sec States and Tasks
 * The Task and State diagram for our the code implemented in our scheduler_main.py file can be seen
 * below. The two tasks were split up for one to control the motor of the robot and the other to
 * control the robot. Code for these states can be seen in the scheduler_main.py code file. 
 * 
 * \image html state_space.png
 * Figure 01: Task and State Diagram for our Robot
 * 
 * \subsection task1 Task 1: Robot Controller
 * State 0 INIT:
 * 
 * This state initializes the robot. This means creating all the necessary flags and classes
 * 
 * State 1 Spin 180:
 * 
 * This state always occurs after INIT. This states uses the controller to turn the robot 180 degrees 
 * to face the target. This is done with the pd_controller, encoder, and motor_driver. Once the
 * controller error is small enough the robot stops and moves to the next state.
 * 
 * State 2 Control:
 * 
 * This state takes the setpoint values from the get_hotspot function calculated by the Thermal Camera
 * Task and moves the robot to the desired location. This is done by setting a shared inter-task 
 * variable img_flg to zero. This tells the Camera tasks it is ready for a new image. Once the 
 * hotspot has been calculated, the value is given to the controller and robot moves to that location.
 * This means that in the five seconds after the turret spins around, it waits for an image, moves to
 * the target location, asks for a new image, waits for the image, and then moves to the new location 
 * until five seconds has passed. After it has found the final target location and fives seconds has
 * passed it stops moving and transitions to the next state. With the scheduler, the robot can move
 * multiple times, depending on how much the target has moved, before FREEZE is called. 
 * 
 * State 3 Shoot:
 * 
 * This state simply uses the servo to pull the trigger and shoot the target. This is done by setting
 * the servo to a position that will pull the trigger and then returning the servo to its default 
 * position. After the trigger has been pulled the code transitions to the next state.
 * 
 * State 4 Return:
 * 
 * This code uses the same control loop as the 180 spin to spin the robot back to zero. 
 * This is done by just sending the controller a negative value of the value used to spin 
 * the robot 180 at the beginning of a duel.
 * 
 * State 5 Stop the Robot:
 * 
 * This state stops the robots movement and then prints some values for us to verify the final target 
 * location. After this state the code is then exited. 
 * 
 * \subsection task2 Task 2: Camera
 * State 0 INIT:
 *
 * This state initializes the camera with code from mlx_cam. This uses the I2C functionality and ports
 * to control the thermal camera.
 * 
 * State 1 Take a Picture:
 * 
 * This photo waits for the inter-task variable image_flag to equal zero. Once the flag is lowered the 
 * state takes a picture, uses the get_hotspot command to find the location of the target in encoder 
 * tics, and then puts that value in the share. The image_flag is then raised to tell the other task
 * there has been a new setpoint value calculated. The state then waits for the image_flag to be
 * lowered again before taking a new image. This is done before the other task exits. 
 *
 */
